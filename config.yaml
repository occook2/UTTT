# AlphaZero Training Configuration

# Training parameters
n_epochs: 25
games_per_epoch: 25
batch_size: 64
learning_rate: 0.001
weight_decay: 0.0001

# Self-play parameters
mcts_simulations: 100
temperature_threshold: 81
temperature: 1.0
c_puct: 1.0
use_multiprocessing: true
num_processes: 5

# Model saving
save_every: 2
checkpoint_dir: "checkpoints"

# Device
device: "cuda"

# Training data management
max_training_samples: 100000

# Symmetry augmentation
use_symmetry_augmentation: true

# UI data saving (separate from training)
save_ui_data: true

# Neural Network Architecture
network:
  in_planes: 7          # Input channels (UTTT state representation)
  channels: 32          # Channels in convolutional layers
  blocks: 3             # Number of residual blocks  
  board_n: 9            # Board size (UTTT is 9x9)
  policy_reduce: 16     # Policy head
  value_hidden: 64      # Value head